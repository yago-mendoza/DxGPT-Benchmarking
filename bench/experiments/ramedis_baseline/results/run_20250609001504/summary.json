{
    "metadata": {
        "experiment_name": "Ramedis Baseline con GPT-4o",
        "llm_configs": {
            "candidate_dx_gpt": {
                "model": "gpt-4o",
                "prompt": "eval-prompts/candidate_prompt.txt"
            },
            "severity_assigner_llm": {
                "model": "gpt-4o",
                "prompt": "eval-prompts/severity_assignment_batch_prompt.txt"
            }
        }
    },
    "semantic_evaluation": {
        "mean_score": 0.7954,
        "standard_deviation": 0.2123,
        "range": {
            "min": 0.3322,
            "max": 1.0
        }
    },
    "severity_evaluation": {
        "mean_score": 0.2254,
        "standard_deviation": 0.1114,
        "range": {
            "min": 0.0,
            "max": 0.6
        }
    }
}