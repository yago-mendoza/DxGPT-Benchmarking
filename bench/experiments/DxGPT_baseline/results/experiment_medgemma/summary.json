{
    "metadata": {
        "experiment_name": "Ramedis Baseline con GPT-4o",
        "llm_configs": {
            "candidate_dx_gpt": {
                "model": "medgemma",
                "prompt": "eval-prompts/candidate_prompt.txt"
            },
            "severity_assigner_llm": {
                "model": "gpt-4o",
                "prompt": "eval-prompts/severity_assignment_batch_prompt.txt"
            }
        }
    },
    "semantic_evaluation": {
        "mean_score": 0.5782,
        "standard_deviation": 0.2294,
        "range": {
            "min": 0.1952,
            "max": 1.0
        }
    },
    "severity_evaluation": {
        "mean_score": 0.4318,
        "standard_deviation": 0.2118,
        "range": {
            "min": 0.0,
            "max": 1.0
        }
    }
}