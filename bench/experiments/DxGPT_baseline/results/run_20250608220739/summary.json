{
    "metadata": {
        "experiment_name": "Ramedis Baseline con GPT-4o",
        "llm_configs": {
            "candidate_dx_gpt": {
                "model": "gpt-4o",
                "prompt": "eval-prompts/candidate_prompt.txt"
            },
            "severity_assigner_llm": {
                "model": "gpt-4o",
                "prompt": "eval-prompts/severity_assignment_batch_prompt.txt"
            }
        }
    },
    "semantic_evaluation": {
        "mean_score": 0.8582,
        "standard_deviation": 0.1989,
        "range": {
            "min": 0.3755,
            "max": 1.0000
        }
    },
    "severity_evaluation": {
        "mean_score": 0.1670,
        "standard_deviation": 0.0779,
        "range": {
            "min": 0.0500,
            "max": 0.4000
        }
    }
}