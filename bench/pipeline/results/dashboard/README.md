# Dashboard de VisualizaciÃ³n - DxGPT Benchmark ğŸ“Š

Este dashboard interactivo permite visualizar, comparar y analizar los resultados de mÃºltiples experimentos de evaluaciÃ³n de modelos de diagnÃ³stico mÃ©dico. Proporciona insights visuales sobre el rendimiento en las dos dimensiones clave: precisiÃ³n semÃ¡ntica y estimaciÃ³n de severidad.

## ğŸ¯ Â¿QuÃ© muestra el Dashboard?

### Vista Principal: GrÃ¡fico de DispersiÃ³n 2D

El grÃ¡fico principal posiciona cada modelo en un espacio bidimensional:

- **Eje X (Severity Score)**: QuÃ© tan bien estima la gravedad (0 = perfecto, 1 = pÃ©simo)
- **Eje Y (Semantic Score)**: QuÃ© tan bien identifica diagnÃ³sticos (0 = pÃ©simo, 1 = perfecto)

**InterpretaciÃ³n visual**:
```
          Semantic Score â†‘
                1.0 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ â—† Ideal             â”‚
                    â”‚   (Alta precisiÃ³n,  â”‚
                    â”‚    baja distancia)  â”‚
                0.5 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚         â—‡           â”‚
                    â”‚     Moderado        â”‚
                    â”‚                     â”‚
                0.0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    0.0       0.5        1.0
                         Severity Score â†’
```

**Cuadrantes**:
- **Superior Izquierda** (ideal): Alta precisiÃ³n diagnÃ³stica + buena estimaciÃ³n de severidad
- **Superior Derecha**: Identifica bien pero estima mal la gravedad
- **Inferior Izquierda**: Estima bien gravedad pero falla en diagnÃ³sticos
- **Inferior Derecha** (peor): Falla en ambas dimensiones

### Visualizaciones Disponibles

1. **Comparison View**: Todos los modelos en un solo grÃ¡fico
2. **Detailed Analysis**: GrÃ¡ficos individuales por modelo
3. **JSON Explorer**: Datos crudos para anÃ¡lisis profundo
4. **Experiment Panel**: Lista interactiva de experimentos

## ğŸš€ CÃ³mo Ejecutar el Dashboard

### OpciÃ³n 1: Script Python Incluido (Recomendado)

```bash
cd bench/pipeline/results/dashboard/
python serve_dashboard.py
```

El script automÃ¡ticamente:
- Detecta todos los experimentos disponibles
- Inicia servidor en puerto 8000
- Abre el navegador (opcional)

### OpciÃ³n 2: Servidor HTTP Simple

```bash
# Con Python
python -m http.server 8000

# Con Node.js
npx http-server -p 8000

# Con PHP
php -S localhost:8000
```

Luego navegar a: http://localhost:8000

### OpciÃ³n 3: Servidor de Desarrollo

Para desarrollo con hot-reload:
```bash
# Instalar live-server globalmente
npm install -g live-server

# Ejecutar
live-server --port=8000
```

## ğŸ“ Estructura de Archivos

```
dashboard/
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ serve_dashboard.py     # Script servidor con auto-detecciÃ³n
â””â”€â”€ scripts/              # AplicaciÃ³n web
    â”œâ”€â”€ index.html        # Interfaz principal
    â”œâ”€â”€ script.js         # LÃ³gica de Chart.js
    â””â”€â”€ style.css         # Estilos responsivos
```

### Datos Esperados

El dashboard busca experimentos en el directorio padre:

```
../experiment_{modelo}_{timestamp}/
    â”œâ”€â”€ summary.json              # MÃ©tricas agregadas
    â”œâ”€â”€ semantic_evaluation.json  # Detalles semÃ¡nticos
    â””â”€â”€ severity_evaluation.json  # Detalles de severidad
```

## ğŸ¨ CaracterÃ­sticas del Dashboard

### 1. Panel de Experimentos (Togglable)

Lista interactiva de todos los experimentos disponibles:
- Checkbox para incluir/excluir del anÃ¡lisis
- InformaciÃ³n del modelo y timestamp
- CÃ³digos de color por tipo de modelo

### 2. Vista de ComparaciÃ³n

GrÃ¡fico scatter principal con:
- **Puntos de datos**: Cada modelo es un punto
- **Tooltips informativos**: Hover para ver detalles
- **Leyenda interactiva**: Click para mostrar/ocultar
- **Zoom y pan**: NavegaciÃ³n interactiva

### 3. AnÃ¡lisis Detallado

Opciones de visualizaciÃ³n:
- **Grid 1x1**: Un grÃ¡fico grande
- **Grid 1x2**: Dos grÃ¡ficos lado a lado
- **Grid 2x2**: Cuatro grÃ¡ficos en cuadrÃ­cula

Tipos de grÃ¡ficos disponibles:
- Scatter plot (severity vs semantic)
- DistribuciÃ³n de scores semÃ¡nticos
- DistribuciÃ³n de scores de severidad
- AnÃ¡lisis optimista vs pesimista

### 4. Explorador JSON

VisualizaciÃ³n estructurada de datos crudos:
- NavegaciÃ³n por Ã¡rbol expandible
- BÃºsqueda dentro del JSON
- ExportaciÃ³n de datos

### 5. Funciones de ExportaciÃ³n

- **Export Chart**: Guarda grÃ¡fico como PNG
- **Copy Data**: Copia datos al portapapeles
- **Download JSON**: Descarga datos completos

## ğŸ“Š InterpretaciÃ³n de Visualizaciones

### GrÃ¡fico Principal: Posicionamiento de Modelos

```javascript
// Ejemplo de interpretaciÃ³n
{
  "GPT-4o": {
    "position": [0.15, 0.89],  // [severity, semantic]
    "interpretation": "Excelente en ambas dimensiones"
  },
  "MedGemma": {
    "position": [0.45, 0.75],
    "interpretation": "Bueno en diagnÃ³stico, moderado en severidad"
  }
}
```

### MÃ©tricas Mostradas

1. **Mean Scores**: Promedio sobre todos los casos
2. **Standard Deviation**: Consistencia del modelo
3. **Range**: Mejor y peor caso
4. **Optimist/Pessimist Ratio**: Tendencia a sub/sobreestimar

### Colores y SÃ­mbolos

- **Azul**: Modelos GPT (OpenAI)
- **Verde**: Modelos mÃ©dicos especializados
- **Naranja**: Modelos open-source
- **Rojo**: Modelos con bajo rendimiento
- **TamaÃ±o del punto**: Proporcional al nÃºmero de casos

## ğŸ”§ PersonalizaciÃ³n

### Modificar Colores de Modelos

En `script.js`:
```javascript
const modelColors = {
    'gpt-4o': 'rgba(54, 162, 235, 0.8)',      // Azul
    'jonsnow': 'rgba(75, 192, 192, 0.8)',     // Verde
    'medgemma': 'rgba(255, 159, 64, 0.8)',    // Naranja
    // AÃ±adir nuevos modelos aquÃ­
};
```

### Ajustar Escalas

```javascript
scales: {
    x: {
        min: 0,
        max: 1,
        title: {
            text: 'Severity Score (lower is better)'
        }
    },
    y: {
        min: 0,
        max: 1,
        title: {
            text: 'Semantic Score (higher is better)'
        }
    }
}
```

### AÃ±adir Nuevas Visualizaciones

1. Crear nueva funciÃ³n en `script.js`:
```javascript
function createCustomChart(containerId, experiments) {
    // Tu lÃ³gica de visualizaciÃ³n
}
```

2. AÃ±adir opciÃ³n en el HTML:
```html
<button onclick="showCustomView()">Mi Vista</button>
```

## ğŸ› SoluciÃ³n de Problemas

### No se cargan experimentos

1. **Verificar servidor HTTP**: No abrir HTML directamente
2. **Revisar consola**: F12 â†’ Console para errores
3. **Validar JSONs**: Cada experimento debe tener los 3 JSONs requeridos
4. **Permisos**: Verificar permisos de lectura en las carpetas

### GrÃ¡ficos no se muestran

1. **Cache del navegador**: Ctrl+F5 para refrescar
2. **CDN de Chart.js**: Verificar conexiÃ³n a internet
3. **Datos vÃ¡lidos**: Revisar que los scores estÃ©n en [0,1]

### ExportaciÃ³n falla

1. **Navegador compatible**: Chrome/Firefox/Edge modernos
2. **TamaÃ±o del canvas**: Reducir cantidad de experimentos
3. **Memoria**: Cerrar otras pestaÃ±as si hay muchos datos

## ğŸš€ CaracterÃ­sticas Avanzadas

### AnÃ¡lisis Comparativo AutomÃ¡tico

El dashboard calcula automÃ¡ticamente:
- **Best performer**: Modelo mÃ¡s cercano a (0, 1)
- **Most consistent**: Menor desviaciÃ³n estÃ¡ndar
- **Best semantic**: Mayor score semÃ¡ntico promedio
- **Best severity**: Menor score de severidad promedio

### Filtros DinÃ¡micos

- Filtrar por rango de fechas
- Filtrar por tipo de modelo
- Filtrar por score mÃ­nimo
- Mostrar solo top N modelos

### IntegraciÃ³n con Pipeline

El dashboard se actualiza automÃ¡ticamente cuando:
- Se ejecutan nuevos experimentos
- Se modifican resultados existentes
- Se aÃ±aden nuevos modelos

## ğŸ“ˆ Mejores PrÃ¡cticas de VisualizaciÃ³n

1. **Comparar similares**: Agrupar modelos de la misma familia
2. **Considerar varianza**: No solo ver promedios
3. **MÃºltiples ejecuciones**: Promediar resultados de varias corridas
4. **Contexto clÃ­nico**: Recordar que menor severidad error puede ser crÃ­tico
5. **Documentar insights**: Usar la funciÃ³n de notas para observaciones

## ğŸ”— ExportaciÃ³n y Reportes

### Generar Reporte AutomÃ¡tico

```python
# generate_report.py
from dashboard import DashboardData

data = DashboardData("../")
report = data.generate_comparison_report(
    models=['gpt-4o', 'jonsnow', 'medgemma'],
    output_format='markdown'
)
```

### IntegraciÃ³n con Notebooks

```python
# En Jupyter
from IPython.display import IFrame
IFrame('http://localhost:8000', width=1000, height=600)
```

## ğŸ¯ Roadmap Futuro

- [ ] Filtros avanzados por fecha/modelo
- [ ] ExportaciÃ³n a Excel/CSV
- [ ] AnÃ¡lisis de tendencias temporales
- [ ] ComparaciÃ³n estadÃ­stica (t-test, ANOVA)
- [ ] Modo presentaciÃ³n fullscreen
- [ ] Temas oscuro/claro
- [ ] API REST para integraciÃ³n

## ğŸ“š Referencias

- [Chart.js Documentation](https://www.chartjs.org/docs/)
- [MetodologÃ­a de EvaluaciÃ³n](../../README.md)
- [Estructura de Resultados](../README.md)

