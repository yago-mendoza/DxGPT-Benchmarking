# Data29 - GestiÃ³n y Procesamiento de Datos MÃ©dicos ğŸ“Š

Este directorio es el corazÃ³n del procesamiento de datos del proyecto. AquÃ­ es donde los datasets mÃ©dicos crudos se transforman en datasets limpios y estructurados que el pipeline de evaluaciÃ³n puede consumir. El nombre "data29" hace referencia a Foundation 29, organizaciÃ³n dedicada a enfermedades raras.

## ğŸ¯ PropÃ³sito

La carpeta `data29` cumple tres funciones fundamentales:

1. **Almacenamiento de datos crudos**: Datasets originales de diferentes fuentes mÃ©dicas
2. **ETL (Extract, Transform, Load)**: Scripts para limpiar y estructurar los datos
3. **Control de calidad**: ValidaciÃ³n de integridad y consistencia (futuro health-checker)

## ğŸ—ï¸ Estructura

```
data29/
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ health-checker/        # Validador de calidad de datos (en desarrollo)
â””â”€â”€ data-repos/           # Repositorio principal de datos
    â”œâ”€â”€ raw/              # Datos crudos sin procesar
    â”‚   â”œâ”€â”€ more.txt
    â”‚   â””â”€â”€ ukranian.csv
    â””â”€â”€ urg_torre & ramedis_bench/
        â”œâ”€â”€ current-data/  # Datos procesados y listos para usar
        â”‚   â”œâ”€â”€ RAMEDIS.json      # Dataset principal para bench
        â”‚   â”œâ”€â”€ urg_torre.json    # Dataset de urgencias
        â”‚   â””â”€â”€ visualisations/   # AnÃ¡lisis visual de los datos
        â””â”€â”€ etl/          # Scripts y procesos de transformaciÃ³n
            â”œâ”€â”€ 25.05/    # VersiÃ³n mayo
            â””â”€â”€ 25.06/    # VersiÃ³n junio (mÃ¡s reciente)
```

## ğŸ“Š Datasets Principales

### RAMEDIS.json
**UbicaciÃ³n**: `data-repos/urg_torre & ramedis_bench/current-data/RAMEDIS.json`

Dataset de casos mÃ©dicos con diagnÃ³sticos diferenciales. Cada caso incluye:
- **id**: Identificador Ãºnico
- **case**: DescripciÃ³n clÃ­nica del paciente
- **diagnoses**: Lista de diagnÃ³sticos correctos (GDX) con:
  - `name`: Nombre del diagnÃ³stico
  - `severity`: Nivel de severidad (S0-S10)
  - `code`: CÃ³digo ICD-10 (cuando aplica)

Ejemplo de estructura:
```json
{
  "id": "RAMEDIS_0001",
  "case": "A 45-year-old male presents with chest pain...",
  "diagnoses": [
    {
      "name": "Myocardial infarction",
      "severity": "S9",
      "code": "I21.9"
    }
  ]
}
```

### urg_torre.json
**UbicaciÃ³n**: `data-repos/urg_torre & ramedis_bench/current-data/urg_torre.json`

Dataset de casos de urgencias hospitalarias con estructura similar pero enfocado en escenarios de emergencia.

## ğŸ”„ Proceso ETL

El proceso de transformaciÃ³n de datos (ETL) se documenta en las carpetas `etl/25.05/` y `etl/25.06/`. Cada versiÃ³n incluye:

### 1. Datos Originales
En `original-csvs/` se encuentran los datasets crudos de diferentes fuentes:
- `test_RAMEDIS.csv`: Casos de diagnÃ³stico diferencial
- `test_HMS.csv`: Casos del Hospital Management System
- `test_LIRICAL.csv`: Casos de enfermedades genÃ©ticas
- `test_critical.csv`, `test_severe.csv`: Casos por severidad

### 2. Scripts de TransformaciÃ³n
Cada subcarpeta en `etl/25.06/` representa una etapa de transformaciÃ³n:

- **ramedis-v2-added-origin-column**: AÃ±ade columna de origen para trazabilidad
- **ramedis-v3-formatting-diagnosis-names**: Normaliza nombres de diagnÃ³sticos
- **ramedis-v4-setting-complexity**: AÃ±ade niveles de complejidad
- **both-rv5-uv7-diagnosis-severity-assessment**: Asigna severidades usando mapping

### 3. Mapeos y TaxonomÃ­as
En `legacy-mappings/`:
- `disease2name.json`: Mapeo de cÃ³digos a nombres de enfermedades
- `hpo2name.json`: Human Phenotype Ontology
- `rare_ramedis_class.jsonl`: ClasificaciÃ³n de enfermedades raras

## ğŸ¥ Health Checker (Futuro)

El directorio `health-checker/` estÃ¡ destinado a contener herramientas de validaciÃ³n de calidad:

### Funcionalidades planeadas:

1. **ValidaciÃ³n de cÃ³digos ICD-10**:
   ```python
   from utils.icd10 import ICD10Taxonomy
   
   def validate_dataset(dataset_path):
       taxonomy = ICD10Taxonomy()
       errors = []
       
       for case in dataset:
           for diagnosis in case['diagnoses']:
               if 'code' in diagnosis:
                   if not taxonomy.get(diagnosis['code']):
                       errors.append(f"Invalid ICD-10: {diagnosis['code']}")
       
       return errors
   ```

2. **VerificaciÃ³n de severidades**:
   - Validar que todas las severidades estÃ©n en rango S0-S10
   - Detectar inconsistencias (ej: "Common cold" con S10)

3. **Integridad de datos**:
   - Casos sin diagnÃ³sticos
   - DiagnÃ³sticos duplicados
   - Campos faltantes o malformados

4. **EstadÃ­sticas de calidad**:
   - DistribuciÃ³n de severidades
   - Cobertura de cÃ³digos ICD-10
   - Balance de tipos de casos

## ğŸ“ˆ Visualizaciones

La carpeta `visualisations/` contiene anÃ¡lisis grÃ¡ficos generados por `stats_new.py`:

- **severity_distribution.png**: Histograma de distribuciÃ³n de severidades
- **diagnostic_codes_distribution.png**: Frecuencia de cÃ³digos ICD-10
- **case_complexity.jpg**: AnÃ¡lisis de complejidad de casos
- **diagnosis_network.png**: Red de relaciones entre diagnÃ³sticos

## ğŸ”§ Uso en el Pipeline

Los datos procesados en `data29` son consumidos por el pipeline de evaluaciÃ³n:

```yaml
# bench/pipeline/config.yaml
dataset_path: "bench/datasets/RAMEDIS.json"
```

El archivo referenciado es una copia del procesado en `data29/data-repos/urg_torre & ramedis_bench/current-data/`.

## ğŸš€ CÃ³mo AÃ±adir Nuevos Datasets

1. **Colocar datos crudos** en `data-repos/raw/`

2. **Crear script ETL**:
   ```python
   # etl/nueva_version/transform.py
   import json
   import pandas as pd
   
   # Leer datos crudos
   df = pd.read_csv('../raw/nuevo_dataset.csv')
   
   # Transformar al formato esperado
   cases = []
   for _, row in df.iterrows():
       case = {
           "id": f"NEW_{row['id']}",
           "case": row['description'],
           "diagnoses": [
               {
                   "name": row['diagnosis'],
                   "severity": assign_severity(row['diagnosis']),
                   "code": get_icd10_code(row['diagnosis'])
               }
           ]
       }
       cases.append(case)
   
   # Guardar
   with open('nuevo_dataset.json', 'w') as f:
       json.dump(cases, f, indent=2)
   ```

3. **Validar con health-checker** (cuando estÃ© implementado)

4. **Copiar a bench/datasets/** para uso en experimentos

## ğŸ“ Notas Importantes

- Los datos mÃ©dicos son sensibles: NO subir datos reales de pacientes
- Mantener trazabilidad: documentar origen y transformaciones
- Versionar cambios: usar carpetas con fechas para ETL
- Validar siempre: ejecutar checks de calidad antes de usar

## ğŸ”— Referencias

- [ICD-10 Browser](https://icd.who.int/browse10/2019/en)
- [Human Phenotype Ontology](https://hpo.jax.org/)
- [Foundation 29](https://www.foundation29.org/)